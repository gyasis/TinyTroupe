---
noteId: "7acbd13047f611f08b8cf32d57ce7e4d"
tags: []

---

I'll help you create a curl command to list the available models from your Ollama server. Based on your config file, I see you're already configured to connect to Ollama at `http://192.168.1.160:11434/v1`.

Let me create the curl command to list the models: 

Here are the available models on your Ollama server:

1. `phi4:latest` (14.7B parameters)
2. `qwen2.5vl:32b` (33.5B parameters)
3. `devstral:latest` (23.6B parameters)
4. `gemma3:27b` (27.4B parameters)
5. `llava:7b` (7B parameters, includes CLIP for vision tasks)
6. `codegemma:latest` (9B parameters)
7. `qwen2.5-coder:32b` (32.8B parameters)
8. `qwq:32b` (32.8B parameters)
9. `qwen2.5-coder:14b` (14.8B parameters)
10. `deepseek-r1:70b` (70.6B parameters)
11. `mistral-nemo:12b` (12.2B parameters)
12. `mistral-small:22b` (22.2B parameters)
13. `mistral:latest` (7.2B parameters)

You have a good variety of models available, ranging from smaller 7B parameter models to large 70B parameter models. Would you like to test any specific model or would you like to know more details about any particular one?